# $$_ Lines starting with # $$_* autogenerated by jup_mini. Do not modify these
# $$_markdown
# % Performance testing results
# 
# no compression, vlen strings
# 2.7GB
# 195ms
# 
# lz4, vlen strings
# 2.9GB
# 203ms
# 
# blosc + lz4, vlen strings
# 2.9GB
# 215ms
# 
# no compression, autochunks, vlen strings
# 3.1GB
# 196ms
# 
# lz4, autochunks, vlen strings
# 3.1GB
# 204ms
# 
# blosc + lz4, autochunks, vlen strings
# 3.2GB
# 210ms
# 
# no chunking, no compression, vlen strings
# 3.4GB
# 195 ms
# 
# no chunking, lz4, vlen strings
# 3.4GB
# 209 ms
# 
# no chunking, lzf, vlen strings
# 3.4GB
# 242 ms
# 
# no chunking, no compression, fixed len strings
# 3.5GB
# 5.29 ms
# 
# no chunking, lzf, fixed len strings
# 3.5GB
# 27.6 ms
# 
# no chunking, lz4, fixed len strings
# 3.6GB
# 15.8ms
# 
# no chunking, blosc, fixed len strings
# 3.6 GB
# 21.5 ms
# $$_end_markdown
# $$_code
# $$_ %%checkall
import h5py
import string
import os
import numpy as np
import pandas as pd
import datetime
from typing import List, Dict, Tuple, Any


def np_arrays_to_hdf5(data: List[Tuple[str, np.ndarray]], 
                      filename: str, 
                      key: str, 
                      dtypes: Dict[str, str] = None, 
                      optimize_vlen_str: bool = True,
                      compression_args: Dict[Any, Any] = None) -> None:
    '''
    Write a list of numpy arrays to hdf5
    data: 
    
    '''
    
    if not len(data): return
    tmp_key = key + '_tmp'
    
    if compression_args is None:
        compression_args = {}
    
    with h5py.File(filename, 'a') as f:
        if tmp_key in f: del f[tmp_key]
        grp = f.create_group(tmp_key)
        for colname, array in data:
            if dtypes is not None and colname in dtypes:
                _dtype = dtypes[colname]
                dtype = np.dtype(_dtype)
                if dtype.kind == 'M':  # datetime
                    dtype = h5py.opaque_dtype(dtype)
                    array = array.astype(dtype)
            else:
                dtype = array.dtype
                if dtype.kind == 'O':  # strings
                    if optimize_vlen_str:
                        max_len = len(max(array, key=len))
                        if max_len < 100:
                            dtype = np.dtype(f'S{max_len}')
                            array = array.astype(dtype)
                        else:
                            dtype = h5py.string_dtype(encoding='utf-8')
                    else:
                        dtype = h5py.string_dtype(encoding='utf-8')
                elif dtype.kind == 'M':  # datetime
                    dtype = h5py.opaque_dtype(dtype)
                    array = array.astype(dtype)
            if colname in grp:
                del grp[colname]
            grp.create_dataset(name=colname, data=array, shape=[len(array)], dtype=dtype, **compression_args)
            
        grp.attrs['type'] = 'dataframe'
        grp.attrs['timestamp'] = str(datetime.datetime.now())
        grp.attrs['rows'] = len(array)
        grp.attrs['columns'] = ','.join([tup[0] for tup in data])

        if key in f: 
            del f[key]
        f.move(tmp_key, key)
        grp.file.flush()
        

def hdf5_to_np_arrays(filename: str, key: str) -> List[Tuple[str, np.ndarray]]:
    ret: List[Tuple[str, np.ndarray]] = []
    with h5py.File(filename, 'r') as f:
        assert key in f, f'{key} not found in {filename}'
        grp = f[key]
        assert 'type' in grp.attrs and grp.attrs['type'] == 'dataframe', f'{key} not a dataframe'
        columns = grp.attrs['columns'].split(',')
        for col in columns:
            array = grp[col][:]
            if array.dtype.kind == 'S':
                # decode bytes to numpy unicode
                dtype = f'U{array.dtype.itemsize}'
                array = array.astype(dtype)
            ret.append((col, array))
    return ret
        
        
def df_to_hdf5(df: pd.DataFrame, filename: str, key: str, dtypes: Dict[str, str] = None, optimize_vlen_str=True) -> None:
    arrays = []
    for column in df.columns:
        arrays.append((column, df[column].values))
    np_arrays_to_hdf5(arrays, filename, key, dtypes, optimize_vlen_str)
    

def hdf5_to_df(filename: str, key: str) -> pd.DataFrame:
    arrays = hdf5_to_np_arrays(filename, key)
    array_dict = {name: array for name, array in arrays}
    return pd.DataFrame(array_dict)


def test_hdf5_to_df():
    size = int(1e6)
    a = np.random.randint(0, 10000, size)
    b = a * 1.1
    letters = np.random.choice(list(string.ascii_letters), (size, 5))
    c = np.empty(size, dtype='O')
    for i, row in enumerate(letters):
        c[i] = ''.join(row)
    d = (a * 1000).astype('M8[m]')

    np_arrays_to_hdf5([("b", b), ("a", a), ("c", c), ("d", d)], 'test.hdf5', 'key1/key2')
    file_size = os.path.getsize('test.hdf5')
    print(f"file size: {file_size / 1e6:.0f} MB")

    def read():
        '''
        for performance testing using timeit
        '''
        with h5py.File('test.hdf5', 'r') as f:
            _ = f['key1/key2/a'][:]
            _ = f['key1/key2/b'][:]
            _ = f['key1/key2/c'][:]
            _ = f['key1/key2/d'][:]

    # %timeit read()
    df_in = pd.DataFrame(dict(a=a, b=b, c=c, d=d))
    df_to_hdf5(df_in, '/tmp/test.hdf5', 'key1/key2', dtypes={'d': 'M8[m]'})
    df_out = hdf5_to_df('/tmp/test.hdf5', 'key1/key2')
    from pandas.testing import assert_frame_equal
    assert_frame_equal(df_in, df_out)
    

if __name__ == '__main__':
    test_hdf5_to_df()
# $$_end_code
